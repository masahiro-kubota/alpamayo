# Alpamayo-R1 ファインチューニング関連スクリプト解説

このドキュメントでは、機械学習の専門知識がない方でも全体の流れと各ファイルの役割が理解できるように、Alpamayo-R1のファインチューニング（追加学習）と評価に使われるスクリプト群を解説します。

---

## 📂 全体の流れ (Big Picture)

このプロジェクトは、**「自動運転AI（Alpamayo-R1）に、特定の状況（例: 急カーブ）での運転を特訓させて、うまくなったかを確認する」** ことが目的です。

料理に例えると、以下のような流れになります：
1.  **`prepare_training_data.py`**: 食材（データ）を買ってきて、料理しやすいように切ってタッパーに詰める（前処理）。
2.  **`train_trajectory_decoder.py`**: シェフ（AIモデル）に新しいレシピを特訓させる（学習）。
3.  **`benchmark_pipeline.sh`**: これら全部を自動で指示するマネージャー。
    - 内部で **`run_comparison_benchmark.py`** を呼び出し、「特訓前のシェフ」と「特訓後のシェフ」に同じ料理を作らせて比較する（評価比較）。
    - 評価には **`evaluate_trajectory_decoder.py`** （実際に料理させる）や **`visualize_eval_results.py`** （盛り付けを写真に撮る）が使われます。

---

## 📜 各スクリプトの解説

### 1. `benchmark_pipeline.sh`
**【役割：現場監督 / 指揮官】**
これ一本実行すれば、データの準備から、AIの評価、結果のグラフ化まで全部自動でやってくれる「自動化スクリプト」です。人間はこれを実行して待つだけです。

**主な処理の流れ**:
- **Step 1**: `prepare_training_data.py` を呼んで、評価用のデータを作ります。
- **Step 2**: `run_comparison_benchmark.py` を呼んで、AIにテストを受けさせます。
- **Step 3**: 最後に「結果はここにあるよ」と教えてくれます。

---

### 2. `prepare_training_data.py`
**【役割：食材の下ごしらえ / データ作成係】**
巨大なデータセット（PhysicalAI-AV Dataset）から必要な部分だけを取り出し、AIが学習・評価できる形式（`.pt`ファイル）に変換します。

**主な関数 (Function Level)**:
- **`process_dataset`**: メインの処理係です。
    1. **`PhysicalAIAVDatasetInterface`**: データ倉庫からデータをダウンロードしてきます。
    2. **`egomotion_interp`**: 車の動き（速度やカーブ）の情報を取得します。「一番カーブがきつい瞬間(`max curvature`)」を自動で探す機能もあります。
    3. **`video_reader.decode_images...`**: カメラ映像（前、左、右など）を画像として取り出します。
    4. **`processor(...)`**: 画像とテキスト（「運転の思考過程を出力して」等の指示）を、AIが読める「トークン」という数値の列に変換します。
    5. **`torch.save`**: 文字通り「保存」します。特訓セットの出来上がりです。

---

### 3. `train_trajectory_decoder.py`
**【役割：特訓道場 / 学習係】**
AIモデルを鍛えるメインのプログラムです。ただし、脳みそ全部を鍛えるのではなく、「運動神経（Trajectory Decoder）」だけを重点的に鍛えます。

**主な関数**:
- **`TrajectoryDataset` & `custom_collate_fn`**: `prepare_training_data.py`で作ったタッパー入りの食材（データ）を、AIが一口で食べられるサイズ（バッチ）に整列させます。
- **`compute_flow_matching_loss`**: **ここが一番重要です！** AIの「手本とのズレ」を計算します。
    - 先生（正解の運転軌跡）と、生徒（AIの予測軌跡）の動きを比べます。
    - **"Flow Matching Loss"** という最新の計算方法を使って、「どれくらい間違っているか（Loss）」を算出します。
- **`train`**: 特訓メニュー全体を管理します。
    - **`Freeze VLM`**: 「目や言語理解（VLM）」の部分は凍結（`Freeze`）して変更しないようにします。余計なことを忘れさせないためです。
    - **`Unfreeze Diffusion Head`**: 「運転の制御（Diffusion Head）」部分だけ解凍（`Unfreeze`）して、学習できるようにします。
    - **`epoch`ループ**: 何回繰り返し練習するか決めます。練習が終わるたびに「セーブデータ（Checkpoint）」を保存します。

---

### 4. `run_comparison_benchmark.py`
**【役割：性能テストの試験官 / 比較係】**
「特訓前のAI」と「特訓後のAI」に同じコースを走らせて、どっちがうまいか白黒つけます。また、「左目と右目を隠した状態（Masked）」でもちゃんと走れるかテストします。

**主な関数**:
- **`is_cached`**: 「このテスト、前にもやらなかった？」と確認します。同じテストなら計算をサボる（キャッシュを使う）賢い機能です。
- **`main`の中のステップ**:
    1. **Baseline Inferences**: 何も特訓していないAIに運転させます。
    2. **FT Inference**: 特訓済み（Fine-Tuned）のAIに運転させます。
- **`visualize(...)`**: 最後に `visualize_eval_results.py` を呼び出して、成績表（比較画像）を作らせます。

---

### 5. `evaluate_trajectory_decoder.py`
**【役割：実際の運転テスト / 推論係】**
このスクリプトは単体でも使えますが、主に試験官（`run_comparison_benchmark.py`）から呼び出されて、「実際に運転してみろ」という指示を実行します。

**主な関数**:
- **`evaluate`**: テスト本番です。
    - **`model.load_state_dict`**: 指定された「特訓の成果（重みデータ）」を脳に読み込みます。
    - **`model.sample_trajectories...`**: ここでAIが考えます。「うーん、画像を見る限り、こう進むべきだ！」と未来の軌跡（Trajectory）を生成します。
- **座標変換 (`Coordinate Transformation`)**:
    - AIは「世界地図上の座標」で考えますが、評価するときは「自分から見て右に何メートル」という「自分中心の座標」のほうがわかりやすいので、計算して変換します。

---

### 6. `visualize_eval_results.py`
**【役割：成績表のグラフ化 / カメラマン】**
数字の羅列だと人間にはわからないので、きれいな図にします。

**主な関数**:
- **`visualize`**:
    - **`plt.subplots`**: 絵を描く画用紙（Canvas）を用意します。
    - **`imshow`**: カメラの映像（左、前、右のカメラ画像）をペタッと貼ります。
    - **`plot` (Trajectory Plot)**: ここがメインです。
        - **緑線**: 正解（人間が実際に運転した軌跡）。
        - **点線**: AIが予測した軌跡。特訓前（青）と特訓後（紫）を重ねて描くことで、「お、特訓後は正解に近づいたな！」と一目でわかるようにします。

---

## 🔧 [Bonus] `src/alpamayo_r1/models/alpamayo_r1.py` の変更点解説

ここでは、モデルの内部コードに加えられた「`self.expert.dtype`」に関する変更について解説します。
これは、**「モデル全体でのデータ型の統一（Precision Consistency）」** を保証するための重要な修正です。

### 変更の理由
AIモデルは計算の精度（桁数）によって「型（dtype）」が異なります（例: `float32`, `bfloat16`）。
メインの脳みそ（Expert/Qwen）は `bfloat16` で動いているのに、新しく追加した手足（Diffusion Head）が `float32` だと、**「型の不一致（Type Mismatch）」でエラー** になったり、メモリを無駄に使ったりします。

### 具体的な変更ポイント
1.  **初期化時 (`__init__`)**:
    - 追加したパーツ（Diffusion, Projection）を、強制的に `expert.dtype`（メインの脳みその型）に合わせるようにしました。
2.  **マスク作成時 (`attention_mask`)**:
    - 計算に使うマスクデータの型も合わせました。
3.  **推論ノイズ生成時 (`sample`)**:
    - 拡散モデルが使う乱数ノイズも同じ型で生成するようにしました。

**一言で言うと**:
「脳みそ、手足、道具、すべての『型』を揃えて、エラーなく効率的に動くようにした」という修正です。
