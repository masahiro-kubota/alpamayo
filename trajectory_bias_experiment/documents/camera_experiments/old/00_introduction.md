# Experiment: Camera Configuration (カメラ構成編)

## 0. 実験の背景 (Context)
**Alpamayo-R1**において、特定のカーブ走行シーンでモデルが頑なに「直進」を選択し続ける問題（**直進バイアス**）が確認されました。
本パートでは、この問題が入力カメラの構成（台数、順序、画像の有無）にどの程度依存しているかを検証します。

---

## 1. カメラ台数の可変性と黒画像入力の問題 (Camera Count Flexibility & Black Screen Issue)

### なぜカメラ台数は自由に変更できるのか
Alpamayo-R1は、**1台のカメラでも4台のカメラでも動作可能**です。これは、**Vision Processorが画像を可変長のトークン列に変換する**ためです。

#### 入力処理の流れ
1. **画像 → パッチ分割 → トークン化**   **参照**: ![Front-Only Result](../../images/front_only_test_f789b390.png)Vision Encoder（ViT: Vision Transformer）が各画像をパッチに分割し、各パッチを1つのトークンに変換します。
   
2. **可変長トークン列の生成**  
   ```
   4カメラ: [カメラ左トークン×K] + [カメラ前トークン×K] + [カメラ右トークン×K] + [カメラTeleトークン×K] = 4K トークン
   1カメラ: [カメラ前トークン×K] = K トークン
   ```

3. **Transformerによる処理**  
   TransformerのSelf-Attentionは**可変長入力を扱える**設計になっているため、トークン数が変わってもモデルは正常に動作します。Position Encodingで各トークンの位置情報（1D/2D RoPE）を付与するだけで、入力サイズの固定は不要です。

#### カメラ順序の固定 (Consistent Camera Ordering)
> [!IMPORTANT]
> 「可変長」ではありますが、**「順序（Permutation）」は不変ではありません。**
> モデルは「1番目の画像ブロック＝左カメラ」「2番目＝正面」といった位置関係を、トークン列の並び順（シーケンス位置）から暗黙的に学習しています。もし推論時にカメラの順番を入れ替えてしまうと、モデルは左右を誤認し、正しく推論できなくなります。

これを防ぐため、実装（`load_physical_aiavdataset.py:L198`）では、カメラ名に基づいて**常に一定の順序でソート**してからモデルに渡すように制御されています。
1. `camera_cross_left` (Index 0)
2. `camera_front_wide` (Index 1)
3. `camera_cross_right` (Index 2)
4. `camera_front_tele` (Index 6)


#### コード上の実装（`helper.py:L50`）
```python
"content": [{"type": "image", "image": frame} for frame in frames]
```
画像リストを動的に処理しているため、N枚の画像を渡すだけでN×Kトークンに自動変換されます。

#### カメラ種別の識別メカニズム (Camera Identification Mechanism)
> [!NOTE]
> 「メッセージに『フロント』というラベルがないのに、なぜモデルはカメラを識別できるのか？」という疑問は非常に鋭い指摘です。

現在の実装では、テキストプロンプトによる指示（例：「次はフロントカメラの画像です」）は**一切行われていません**。モデルは以下の2つの情報のみでカメラを特定しています。

1. **視覚的特徴の認識 (Visual Features)**:
   * 各カメラは、視野角 (FOV)、レンズの歪み、ボンネットの映り込み、設置角度などが異なります。
   * 自己教師あり学習や事前学習を通じて、モデルは「この見え方の画像は車両の前方である」といった**視覚的コンテキストを直接理解**しています。
2. **シーケンス上の相対位置 (Positional Prior)**:
   * 学習時、画像は常に **[左・前・右・Tele]** の順序で並べられた 16 画像ブロックとして入力されています。
   * Transformerはこの「並び順」を位置エンコーディング (RoPE) を通じて捉えており、暗黙的に「1番目の画像ブロック＝左」というバイアスを持っています。

#### 1枚だけ入力した場合のリスク
もしフロントカメラ1枚（4フレーム）だけを先頭に置いて入力した場合、モデル内部では「1番目のブロック」として処理されます。
* **視覚が勝つ場合**: 「見え方がフロントだからフロントだ」と正しく認識し、CoTも正常に出力されます。
* **位置バイアスが勝つ場合**: 「1番目に来たからこれは左カメラのはずだ」と誤認し、左車線への偏りや、矛盾したReasoningが発生するリスクがあります。

これを避けるための最も安全な方法は、**推論時も常に全カメラ分（4カメラ分）の画像スロットを確保**するか、あるいはモデルに「どのカメラの画像か」を明示するなどの工夫が必要ですが、現状のAlpamayo-R1（10B）のベースプロンプトはそこを「視覚」と「順序」に頼っている状態です。

---

### なぜ黒画像入力はあまり意味がないのか（理論的考察）

「中央カメラだけを使いたいなら、左右を黒画像にすればいいのでは？」という発想は自然ですが、技術的には以下の理由で**推奨されません**。

#### 1. 分布外データ (Out-of-Distribution) 問題
*   **学習データとの乖離**: モデルは学習中に「黒画像」を見たことがありません。ニューラルネットワークは黒画像を「無」として無視するのではなく、**「未知の異常テクスチャ」**として処理します。
*   **予期しない振る舞い**: モデルは黒画像から何らかの特徴量（「暗い壁」や「異常空間」）を抽出し、保守的な直進行動を引き起こす可能性が高いです。

#### 2. Attention機構の非効率性
*   **Attentionの浪費**: 左右が黒画像であっても、Transformerはそこに計算リソースを割り当てます。
*   **Softmax正規化の問題**: Attentionの重みは合計1.0に正規化されるため、黒画像トークンにも「0ではない重み」が割り当てられます。結果として、**本来中央カメラに集中すべきリソースが、無意味な黒画像トークンに吸収**され、判断力が低下します。

#### 3. 空間認識の破損
*   **空間的連続性の喪失**: VLAモデルは複数カメラで周囲空間を認識するように学習されています。左右を黒くすると、モデルは「左右に障害物」や「センサー異常」と誤解釈し、**安全側（直進/停止）に倒すバイアス**が働きます。

---

## 2. 実験結果概要 (Summary of Results)
（詳細は各実験レポートを参照）

*   **フロント1枚**: 位置不整合により制御ロジックが破綻（直進固定）。
*   **黒画像パッド**: OOD（分布外データ）として処理され、精度が大幅に低下。
*   **全カメラ**: 最も適切な挙動を示すが、それでも学習データのバイアスにより直進傾向が残る場合がある。

結論として、**常に学習時と同じ4カメラ構成（順序含む）を維持することが安定稼働の絶対条件**です。
