# Experiment 00: Introduction (Background & Problem Definition)

## 1. 背景 (Background)
**Alpamayo-R1** は、視覚情報から状況を理解し（Reasoning）、その結果に基づいて行動計画（Trajectory）を生成する自律走行用VLA（Vision-Language-Action）モデルです。
しかし、特定のカーブ走行シーンにおいて、モデルが頑なに「直進」を選択し続ける問題（**直進バイアス**）が確認されました。

## 2. 課題: 直進バイアスと不整合 (The Core Problem)
予備実験において、以下の現象が観測されています。
*   **Reasoning (思考)**: 「前方右カーブあり。操舵が必要」と正しく認識できている。
*   **Action (行動)**: 思考内容に反して、生成される軌道は「直進」し、壁に衝突または車線を逸脱する。

これは単なる予測ミスではなく、VLAモデル特有の課題です。**[Alpamayo-R1の論文 (arXiv:2511.00088)](https://arxiv.org/abs/2511.00088)** では、この問題を **"Reasoning-Action Consistency" (思考と行動の一貫性)** の欠如として扱っており、強化学習を用いて "reasoning-action consistency" を強化することが主要な技術的取り組みとされています。

また、他のVLA研究、特に **["Do What You Say" (Wu et al., 2025)](https://arxiv.org/abs/2502.01828)** では、同様の課題を **"Embodied CoT Faithfulness Gap" (身体的思考連鎖の誠実性の欠如)** として定義し、言語理解と物理的身体性（Embodiment）の結合の問題として議論されています。

## 3. アプローチ: 推論パラメータによる解決の試み (Approach)
本実験シリーズでは、モデルの再学習（Fine-tuning）を行わず、ユーザーが**推論時（Inference-time）に手軽に変更可能なパラメータ**のみを調整することで、この問題を解決できるかを検証します。

### 対象パラメータ (Target Tunable Parameters)
以下の4つのパラメータに焦点を当てます。
1.  **Temperature**: 生成の多様性制御
2.  **Prompt**: 入力指示による思考誘導
3.  **Num Samples**: 生成候補数の増加による良質軌道の探索
4.  **Top-P**: 確率分布のサンプリング範囲調整

これらのパラメータ調整によってバイアスが緩和されるのか、あるいはモデルの学習特性として固定化されているのかを明らかにします。

### 調査対象外のパラメータ (Out of Scope)
**Input History Length (入力履歴長)**:
デフォルトの **16 step** からの変更は本調査の対象外とします。
*   **理由**: モデルが固定長の履歴トークン（48 token = 16 steps）を前提に学習されており、推論コードやデータパイプラインもこの設定に強く依存（ハードコード）しているため。再学習なしでの変更はモデルの想定入力分布（Distribution）を大きく崩すリスクがあります。

## 4. カメラ台数の可変性と黒画像入力の問題 (Camera Count Flexibility & Black Screen Issue)

### なぜカメラ台数は自由に変更できるのか
Alpamayo-R1は、**1台のカメラでも4台のカメラでも動作可能**です。これは、**Vision Processorが画像を可変長のトークン列に変換する**ためです。

#### 入力処理の流れ
1. **画像 → パッチ分割 → トークン化**  
   Vision Encoder（ViT: Vision Transformer）が各画像をパッチに分割し、各パッチを1つのトークンに変換します。
   
2. **可変長トークン列の生成**  
   ```
   4カメラ: [カメラ左トークン×K] + [カメラ前トークン×K] + [カメラ右トークン×K] + [カメラTeleトークン×K] = 4K トークン
   1カメラ: [カメラ前トークン×K] = K トークン
   ```

3. **Transformerによる処理**  
   TransformerのSelf-Attentionは**可変長入力を扱える**設計になっているため、トークン数が変わってもモデルは正常に動作します。Position Encodingで各トークンの位置情報を付与するだけで、入力サイズの固定は不要です。

#### コード上の実装（`helper.py:L50`）
```python
"content": [{"type": "image", "image": frame} for frame in frames]
```
画像リストを動的に処理しているため、N枚の画像を渡すだけでN×Kトークンに自動変換されます。

---

### なぜ黒画像入力はあまり意味がないのか（理論的考察）

「中央カメラだけを使いたいなら、左右を黒画像にすればいいのでは？」という発想は自然ですが、技術的には以下の理由で**推奨されません**。

#### 1. 分布外データ (Out-of-Distribution) 問題
*   **学習データとの乖離**: モデルは学習中に「黒画像」を見たことがありません。ニューラルネットワークは黒画像を「無」として無視するのではなく、**「未知の異常テクスチャ」**として処理します。
*   **予期しない振る舞い**: モデルは黒画像から何らかの特徴量（「暗い壁」や「異常空間」）を抽出し、保守的な直進行動を引き起こす可能性が高いです。

#### 2. Attention機構の非効率性
*   **Attentionの浪費**: 左右が黒画像であっても、Transformerはそこに計算リソースを割り当てます。
*   **Softmax正規化の問題**: Attentionの重みは合計1.0に正規化されるため、黒画像トークンにも「0ではない重み」が割り当てられます。結果として、**本来中央カメラに集中すべきリソースが、無意味な黒画像トークンに吸収**され、判断力が低下します。

#### 3. 空間認識の破損
*   **空間的連続性の喪失**: VLAモデルは複数カメラで周囲空間を認識するように学習されています。左右を黒くすると、モデルは「左右に障害物」や「センサー異常」と誤解釈し、**安全側（直進/停止）に倒すバイアス**が働きます。

---

### 実験: 左右カメラ黒画像化（一応試してみた結果）

上記の理論的懸念があるものの、「サイドカメラ情報が悪さをしているのか？」を診断するため、実験を行いました。

#### 設定
*   **仮説**: 学習時と同じ4カメラ入力（左・前Wide・右・前Teleのうち、左右を黒画像に置き換え）にすることで、Tensor形状起因の問題を解消できるか。
*   **コマンド**:
    ```bash
    python debug_viz.py \
      --multicam \
      --num_samples 1 \
      --output debug_multicam_4cam.png
    ```

#### 結果
*   **軌道**: やや左に寄る (Max Dev **~1.38m**)
*   **CoT**: "Adapt speed for the right curve because construction barrier..."（カーブを認識）
*   **ログ参照**: `viz_multicam_4cam.log`

#### 考察
4カメラ構成では、予想外に**約1.4mの横方向偏差**が観測されました。これは3カメラ実験（0.27m）よりも大きく、Top-P=1.0実験（0.95m）を上回る最大値です。

ただし、この偏差が「右カーブへの追従」なのか「黒画像によるOOD起因のランダムな振る舞い」なのかは判別困難です。CoTでは「Right curve」を認識しているものの、実際の軌跡は**左に寄っている**ため、理論通り「黒画像入力では直進バイアスは解消されない」という結論が支持されます。

これは、サイドカメラの視覚情報自体が問題なのではなく、**モデルの学習データや内部表現に起因する構造的な問題**であることを示唆しています。

---

### 対比: なぜ履歴長は変えられないのか
カメラ台数とは対照的に、**履歴長（16ステップ）は固定**です。

```python
num_traj_token = 48  # ← ハードコードされた固定値
```

モデルは「16ステップの3D座標データ」を「固定48トークン」に圧縮する専用の**Projector（射影層）**を持っており、この層は固定サイズ入力を前提に学習されているため、変更するとエラーが発生します。

---

### まとめ
*   **カメラ台数**: Vision Processorが動的にトークン列を生成 → **変更可能**
*   **黒画像入力**: OOD・Attention浪費・空間認識破損により → **推奨されない**
*   **履歴長**: 固定サイズProjectorに依存 → **変更不可**

もし「中央カメラだけを見てほしい」のであれば、黒画像を入力するのではなく、**モデルの構成変更（Attention Maskで左右を無視、または単眼モデルとして再学習）**が必要です。
