# Qwen2.5 Technical Report

Qwen2.5に関する論文の要約です。本モデルは、Qwenシリーズの最新版であり、18兆トークンでの事前学習と100万サンプル以上でのSFT、多段階強化学習により大幅に改善されています。

## アブストラクト (Abstract)
**内容まとめ**:
本論文ではQwen2.5シリーズを紹介します。前世代と比較して、事前学習とポストトレーニングの両方で大幅に改善されています：
1.  **事前学習**: 高品質な事前学習データセットを7兆トークンから**18兆トークン**に拡大。常識、専門知識、推論能力の強固な基盤を提供。
2.  **ポストトレーニング**: 100万サンプル以上の精巧なSFT、オフライン学習DPOとオンライン学習GRPOを含む多段階強化学習を実施。人間の嗜好、長文生成、構造化データ分析、指示追従が大幅に向上。
3.  **モデル提供**: オープンウェイト（0.5B/1.5B/3B/7B/14B/32B/72B）とAPI提供のMoE（Qwen2.5-Turbo/Plus）を提供。
4.  **性能**: Qwen2.5-72B-InstructはLlama-3-405B-Instruct（約5倍大きい）と競争的な性能を達成。

## 1. イントロダクション (Introduction)
**内容まとめ**:
AGIの実現に向けて、大規模基盤モデルが急速に発展しています。Qwen2.5の主な改善点：
- **Better in Size**: 0.5B〜72Bに加え、3B/14B/32Bモデルを追加。MoEモデルとして精度・レイテンシ・コストのバランスが良いTurbo/Plusを提供。
- **Better in Data**: 事前学習データを7T→18Tトークンに拡大。知識、コーディング、数学に注力。ポストトレーニングは100万サンプル（SFT/DPO/GRPO）。
- **Better in Use**: 生成長を2K→8Kトークンに拡大。構造化入出力（テーブル、JSON）のサポート強化。Qwen2.5-Turboは100万トークンのコンテキスト長に対応。

## 2. アーキテクチャ & トークナイザー (Architecture & Tokenizer)
**内容まとめ**:
Qwen2.5シリーズはDenseモデル（オープンソース）とMoEモデル（API）で構成：

*   **Denseモデルアーキテクチャ**: Qwen2と同様のTransformerベースdecoderアーキテクチャ。
    - **Grouped Query Attention (GQA)**: 効率的なKVキャッシュ利用
    - **SwiGLU活性化関数**
    - **Rotary Positional Embeddings (RoPE)**
    - **QKV-bias + RMSNorm with pre-normalization**
*   **MoEモデル**: DenseモデルのFFN層をMoE層（複数エキスパート + ルーティング機構）に置換。Fine-grained expert segmentation、Shared expert routingを採用。
*   **トークナイザー**: Byte-level BPE、語彙サイズ151,643。コントロールトークンを3→22に拡張。

| モデル | Layers | Heads (Q/KV) | Context/Generation Length |
|--------|--------|--------------|---------------------------|
| 0.5B | 24 | 14/2 | 32K/8K |
| 7B | 28 | 28/4 | 128K/8K |
| 72B | 80 | 64/8 | 128K/8K |

## 3. 事前学習 (Pre-training)
**内容まとめ**:

*   **3.1 事前学習データ**:
    - **より良いデータフィルタリング**: Qwen2-Instructモデルを品質フィルターとして使用し、多次元分析で評価・スコアリング。
    - **より良い数学・コードデータ**: Qwen2.5-MathとQwen2.5-Coderのデータを統合。
    - **より良い合成データ**: Qwen2-72B-InstructとQwen2-Math-72B-Instructで合成データ生成。報酬モデルで品質フィルタリング。
    - **より良いデータ混合**: ドメイン別に分類・バランス調整。Eコマース・SNS・エンタメをダウンサンプリング、技術・科学・学術をアップサンプリング。
    - 結果: **7T → 18兆トークン**に拡大。
*   **3.2 ハイパーパラメータスケーリング則**: モデルサイズNとデータサイズDに基づいて最適な学習率µとバッチサイズBを予測。
*   **3.3 ロングコンテキスト事前学習**:
    - 2段階アプローチ: 4,096トークン → 32,768トークン
    - RoPEベース周波数: 10,000 → 1,000,000（ABF技術）
    - Turbo: 4段階拡張（32K → 64K → 128K → 256K）、ベース周波数10,000,000
    - YARN + DCA（Dual Chunk Attention）で推論時4倍のシーケンス長を実現（Turbo: 100万トークン、他: 131,072トークン）

## 4. ポストトレーニング (Post-training)
**内容まとめ**:

*   **4.1 教師あり微調整 (SFT)**: 100万以上のサンプルで以下を強化。
    - **長文生成**: 最大8,192トークン出力。Back-translation技術でクエリ生成。
    - **数学**: Qwen2.5-MathのCoTデータ。Rejection sampling + 報酬モデリング。
    - **コーディング**: Qwen2.5-Coderのデータ。40言語対応、マルチリンガルサンドボックスで検証。
    - **指示追従**: コードベース検証フレームワーク。LLMが検証コードとユニットテストを生成。
    - **構造化データ理解**: テーブルQA、事実検証、エラー修正、推論チェーン付き。
    - **論理推論**: 70,000の多様なクエリ。演繹・帰納・類推・因果・統計推論。
    - **クロスリンガル転移**: 高リソース言語から低リソース言語へ翻訳。
    - **ロバストなシステム指示**: 数百の汎用システムプロンプトで多様性向上。
*   **4.2 オフラインRL (Offline RL)**: 数学、コーディング、指示追従、論理推論などの客観的クエリに対して**DPO**を適用。約150,000ペア。
*   **4.3 オンラインRL (Online RL)**: 報酬モデルを用いた**GRPO**。Truthfulness、Helpfulness、Conciseness、Relevance、Harmlessness、Debiasingの基準で最適化。
*   **4.4 ロングコンテキスト微調整**: 2段階（短い指示 → 短い+長い指示）。RLは短い指示のみでも長文タスクの人間嗜好整合を改善。

## 5. 評価 (Evaluation)
**内容まとめ**:

*   **5.1 ベースモデル**:
    - **Qwen2.5-72B**: Llama-3-405Bと比較して1/5のパラメータで同等性能。MMLU 86.1、MATH 64.4、HumanEval 59.1。
    - **Qwen2.5-Plus**: MMLU-Pro 64.0（Qwen2.5-72Bより5.9ポイント高い）。
    - **Qwen2.5-32B**: MATH 57.7、MBPP 84.5でQwen1.5-32Bを大幅に上回る。
    - **Qwen2.5-7B**: 非埋め込みパラメータ6.5BでMMLU 74.2、MATH 49.8、HumanEval 57.9。
*   **5.2 指示調整モデル**:
    - **Qwen2.5-72B-Instruct**: MMLU-Pro 73.3、MATH 83.1、HumanEval 86.6、Arena-Hard 81.4。Llama-3.1-405B-Instructに匹敵。
    - **Qwen2.5-Turbo**: GPT-4o-miniと競争的。MMLU-Pro 64.5、MATH 80.0。
    - **Qwen2.5-Plus**: MMLU-Pro 71.1、MATH 84.7、Arena-Hard 81.4で高い性能。
*   **ロングコンテキスト評価**: Qwen2.5-Turboは100万トークンのNeedle-in-a-Haystackで99.9%の検索精度を達成。

## 6. 結論 (Conclusion)
**内容まとめ**:
Qwen2.5は18兆トークンでの事前学習と、SFT・多段階RLを含む洗練されたポストトレーニングにより、LLMの大幅な進歩を達成しました。人間嗜好整合、長文生成、構造化データ分析で優れています。

主な成果：
- Qwen2.5-72B-Instructは6倍大きいLlama-3-405B-Instructに匹敵
- 0.5B〜72Bのオープンウェイトモデルと、コスト効率の良いMoEモデル（Turbo/Plus）を提供
- Qwen2.5-Math、Qwen2.5-Coder、QwQ、マルチモーダルモデルなど特化モデルの基盤として機能

今後の方向性：
- より広範・多様・高品質なデータでのベース・指示調整モデルの反復改良
- テキスト・視覚・聴覚を統合したマルチモーダルモデルの開発
- 推論計算リソースの戦略的スケーリングによる推論能力の強化
