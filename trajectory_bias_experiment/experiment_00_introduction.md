# Experiment 00: Introduction (Background & Problem Definition)

## 1. 背景 (Background)
**Alpamayo-R1** は、視覚情報から状況を理解し（Reasoning）、その結果に基づいて行動計画（Trajectory）を生成する自律走行用VLA（Vision-Language-Action）モデルです。
しかし、特定のカーブ走行シーンにおいて、モデルが頑なに「直進」を選択し続ける問題（**直進バイアス**）が確認されました。

## 2. 課題: 直進バイアスと不整合 (The Core Problem)
予備実験において、以下の現象が観測されています。
*   **Reasoning (思考)**: 「前方右カーブあり。操舵が必要」と正しく認識できている。
*   **Action (行動)**: 思考内容に反して、生成される軌道は「直進」し、壁に衝突または車線を逸脱する。

これは単なる予測ミスではなく、VLAモデル特有の課題です。**[Alpamayo-R1の論文 (arXiv:2511.00088)](https://arxiv.org/abs/2511.00088)** では、この問題を **"Reasoning-Action Consistency" (思考と行動の一貫性)** の欠如として扱っており、強化学習を用いて "reasoning-action consistency" を強化することが主要な技術的取り組みとされています。

また、他のVLA研究、特に **["Do What You Say" (Wu et al., 2025)](https://arxiv.org/abs/2502.01828)** では、同様の課題を **"Embodied CoT Faithfulness Gap" (身体的思考連鎖の誠実性の欠如)** として定義し、言語理解と物理的身体性（Embodiment）の結合の問題として議論されています。

## 3. アプローチ: 推論パラメータによる解決の試み (Approach)
本実験シリーズでは、モデルの再学習（Fine-tuning）を行わず、ユーザーが**推論時（Inference-time）に手軽に変更可能なパラメータ**のみを調整することで、この問題を解決できるかを検証します。

### 対象パラメータ (Target Tunable Parameters)
以下の4つのパラメータに焦点を当てます。
1.  **Temperature**: 生成の多様性制御
2.  **Prompt**: 入力指示による思考誘導
3.  **Num Samples**: 生成候補数の増加による良質軌道の探索
4.  **Top-P**: 確率分布のサンプリング範囲調整

これらのパラメータ調整によってバイアスが緩和されるのか、あるいはモデルの学習特性として固定化されているのかを明らかにします。

### 調査対象外のパラメータ (Out of Scope)
**Input History Length (入力履歴長)**:
デフォルトの **16 step** からの変更は本調査の対象外とします。
*   **理由**: モデルが固定長の履歴トークン（48 token = 16 steps）を前提に学習されており、推論コードやデータパイプラインもこの設定に強く依存（ハードコード）しているため。再学習なしでの変更はモデルの想定入力分布（Distribution）を大きく崩すリスクがあります。

## 4. カメラ台数の可変性と黒画像入力の問題 (Camera Count Flexibility & Black Screen Issue)

### なぜカメラ台数は自由に変更できるのか
Alpamayo-R1は、**1台のカメラでも4台のカメラでも動作可能**です。これは、**Vision Processorが画像を可変長のトークン列に変換する**ためです。

#### 入力処理の流れ
1. **画像 → パッチ分割 → トークン化**  
   Vision Encoder（ViT: Vision Transformer）が各画像をパッチに分割し、各パッチを1つのトークンに変換します。
   
2. **可変長トークン列の生成**  
   ```
   4カメラ: [カメラ左トークン×K] + [カメラ前トークン×K] + [カメラ右トークン×K] + [カメラTeleトークン×K] = 4K トークン
   1カメラ: [カメラ前トークン×K] = K トークン
   ```

3. **Transformerによる処理**  
   TransformerのSelf-Attentionは**可変長入力を扱える**設計になっているため、トークン数が変わってもモデルは正常に動作します。Position Encodingで各トークンの位置情報（1D/2D RoPE）を付与するだけで、入力サイズの固定は不要です。

#### カメラ順序の固定 (Consistent Camera Ordering)
> [!IMPORTANT]
> 「可変長」ではありますが、**「順序（Permutation）」は不変ではありません。**
> モデルは「1番目の画像ブロック＝左カメラ」「2番目＝正面」といった位置関係を、トークン列の並び順（シーケンス位置）から暗黙的に学習しています。もし推論時にカメラの順番を入れ替えてしまうと、モデルは左右を誤認し、正しく推論できなくなります。

これを防ぐため、実装（`load_physical_aiavdataset.py:L198`）では、カメラ名に基づいて**常に一定の順序でソート**してからモデルに渡すように制御されています。
1. `camera_cross_left` (Index 0)
2. `camera_front_wide` (Index 1)
3. `camera_cross_right` (Index 2)
4. `camera_front_tele` (Index 6)


#### コード上の実装（`helper.py:L50`）
```python
"content": [{"type": "image", "image": frame} for frame in frames]
```
画像リストを動的に処理しているため、N枚の画像を渡すだけでN×Kトークンに自動変換されます。

#### カメラ種別の識別メカニズム (Camera Identification Mechanism)
> [!NOTE]
> 「メッセージに『フロント』というラベルがないのに、なぜモデルはカメラを識別できるのか？」という疑問は非常に鋭い指摘です。

現在の実装では、テキストプロンプトによる指示（例：「次はフロントカメラの画像です」）は**一切行われていません**。モデルは以下の2つの情報のみでカメラを特定しています。

1. **視覚的特徴の認識 (Visual Features)**:
   * 各カメラは、視野角 (FOV)、レンズの歪み、ボンネットの映り込み、設置角度などが異なります。
   * 自己教師あり学習や事前学習を通じて、モデルは「この見え方の画像は車両の前方である」といった**視覚的コンテキストを直接理解**しています。
2. **シーケンス上の相対位置 (Positional Prior)**:
   * 学習時、画像は常に **[左・前・右・Tele]** の順序で並べられた 16 画像ブロックとして入力されています。
   * Transformerはこの「並び順」を位置エンコーディング (RoPE) を通じて捉えており、暗黙的に「1番目の画像ブロック＝左」というバイアスを持っています。

#### 1枚だけ入力した場合のリスク
もしフロントカメラ1枚（4フレーム）だけを先頭に置いて入力した場合、モデル内部では「1番目のブロック」として処理されます。
* **視覚が勝つ場合**: 「見え方がフロントだからフロントだ」と正しく認識し、CoTも正常に出力されます。
* **位置バイアスが勝つ場合**: 「1番目に来たからこれは左カメラのはずだ」と誤認し、左車線への偏りや、矛盾したReasoningが発生するリスクがあります。

これを避けるための最も安全な方法は、**推論時も常に全カメラ分（4カメラ分）の画像スロットを確保**するか、あるいはモデルに「どのカメラの画像か」を明示するなどの工夫が必要ですが、現状のAlpamayo-R1（10B）のベースプロンプトはそこを「視覚」と「順序」に頼っている状態です。

---

### なぜ黒画像入力はあまり意味がないのか（理論的考察）

「中央カメラだけを使いたいなら、左右を黒画像にすればいいのでは？」という発想は自然ですが、技術的には以下の理由で**推奨されません**。

#### 1. 分布外データ (Out-of-Distribution) 問題
*   **学習データとの乖離**: モデルは学習中に「黒画像」を見たことがありません。ニューラルネットワークは黒画像を「無」として無視するのではなく、**「未知の異常テクスチャ」**として処理します。
*   **予期しない振る舞い**: モデルは黒画像から何らかの特徴量（「暗い壁」や「異常空間」）を抽出し、保守的な直進行動を引き起こす可能性が高いです。

#### 2. Attention機構の非効率性
*   **Attentionの浪費**: 左右が黒画像であっても、Transformerはそこに計算リソースを割り当てます。
*   **Softmax正規化の問題**: Attentionの重みは合計1.0に正規化されるため、黒画像トークンにも「0ではない重み」が割り当てられます。結果として、**本来中央カメラに集中すべきリソースが、無意味な黒画像トークンに吸収**され、判断力が低下します。

#### 3. 空間認識の破損
*   **空間的連続性の喪失**: VLAモデルは複数カメラで周囲空間を認識するように学習されています。左右を黒くすると、モデルは「左右に障害物」や「センサー異常」と誤解釈し、**安全側（直進/停止）に倒すバイアス**が働きます。

---

### 実験: カメラ構成による動作の比較 (Comparative Analysis)

同一の右カーブシーン（Clip: `f789b390`）を用いて、入力カメラの構成を変えた際の挙動を比較しました。

#### 1. フロントカメラ1枚のみ (Front-only)
*   **設定**: フロントカメラのみを「1番目の画像ブロック」として入力。
*   **結果**: **Max Lateral Deviation: 0.009m** (ほぼ完全な直進)
*   **考察**: 位置エンコーディングの不整合により、モデルの横方向制御ロジックが完全に機能不全に陥っている。CoTでは「Right curve」と言いつつ、行動が伴わない。
*   **参照**: ![Front-Only Result](file:///workspace/alpamayo/trajectory_bias_experiment/front_only_test_f789b390.png)

#### 2. 黒・前・黒・黒 (Black-padded / 4-cam mode)
*   **設定**: フロントカメラを「2番目の位置」に配置し、他を黒画像で埋める。
*   **結果**: **Max Lateral Deviation: 1.377m** (わずかに右へ動くが不十分)
*   **考察**: フロントカメラが「正しい位置（2番目のスロット）」に来ることで、横方向の制御ロジックが部分的に活性化。しかし、黒画像のOOD効果により精度は依然として低い。
*   **ログ参照**: `viz_multicam_4cam.log`

#### 3. 全カメラあり (Full Multi-cam)
*   **設定**: 4カメラ全てを正しい順序で入力（デフォルト）。
*   **結果**: **Max Lateral Deviation: 9.493m** (カーブに追従)
*   **考察**: モデル本来の性能。サイドカメラの情報と正しい位置情報の相乗効果により、適切な軌道を生成。
*   **ログ参照**: `single_curve_test1.log`

---

### まとめ: カメラ入力の「三悪」
1.  **フロント1枚**: 位置不整合により制御ロジックが死ぬ（直進固定）。
2.  **黒画像パッド**: 位置は合うが、黒画像（OOD）がノイズとなり精度が壊滅。
3.  **カメラ順序ミス**: 左右の見え方が逆転し、逆方向へ突っ込むなどの危険な挙動。

結論として、Alpamayo-R1において「フロントだけを見る」という設定を再学習なしで実現するのは極めて困難であり、**常に学習時と同じ4カメラ構成（順序含む）を維持することが安定稼働の絶対条件**です。

#### 結果
*   **軌道**: やや左に寄る (Max Dev **~1.38m**)
*   **CoT**: "Adapt speed for the right curve because construction barrier..."（カーブを認識）
*   **ログ参照**: `viz_multicam_4cam.log`

#### 考察
4カメラ構成では、予想外に**約1.4mの横方向偏差**が観測されました。これは3カメラ実験（0.27m）よりも大きく、Top-P=1.0実験（0.95m）を上回る最大値です。

ただし、この偏差が「右カーブへの追従」なのか「黒画像によるOOD起因のランダムな振る舞い」なのかは判別困難です。CoTでは「Right curve」を認識しているものの、実際の軌跡は**左に寄っている**ため、理論通り「黒画像入力では直進バイアスは解消されない」という結論が支持されます。

これは、サイドカメラの視覚情報自体が問題なのではなく、**モデルの学習データや内部表現に起因する構造的な問題**であることを示唆しています。

---

### 対比: なぜ履歴長は変えられないのか
カメラ台数とは対照的に、**履歴長（16ステップ）は固定**です。

```python
num_traj_token = 48  # ← ハードコードされた固定値
```

モデルは「16ステップの3D座標データ」を「固定48トークン」に圧縮する専用の**Projector（射影層）**を持っており、この層は固定サイズ入力を前提に学習されているため、変更するとエラーが発生します。

---

### まとめ
*   **カメラ台数**: 変更可能（Vision Processorが動的にトークン生成）
*   **カメラ順序**: **固定必須**（ソートにより順序の不整合を防止）
*   **黒画像入力**: 推奨されない（OOD・Attention浪費・空間認識破損）
*   **履歴長**: 変更不可（固定サイズProjectorに依存）

もし「中央カメラだけを見てほしい」のであれば、黒画像を入力するのではなく、**モデルの構成変更（Attention Maskで左右を無視、または単眼モデルとして再学習）**が必要です。
